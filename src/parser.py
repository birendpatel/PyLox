# Copyright (C) 2021 Biren Patel
# MIT License
# Generate an abstract syntax tree via a recusive descent parser

from src.error import ErrorHandler
from src.tokenizer import Token, TokenType
from src.node import Binary, Unary, Literal, Grouping

class Parser():
    def __init__(self):
        """\
        convert a list of tokens to an abstract syntax tree
        @i: tokens index
        @ast: abstract syntax tree generated by self.expression()
        """
        self.err = ErrorHandler()
        self.tokens = []
        self.i = 0
        self.ast = None

    def curr_type(self):
        """\
        helper function: returns token type of token at current list index
        """
        token = self.tokens[self.i]
        return token.type

    def curr_token(self):
        """\
        helper function: syntactic sugar to fetch current token
        """
        return self.tokens[self.i]

    def advance(self):
        """\
        helper function: syntactic sugar for iteration over the tokens list
        """
        assert(self.i + 1 < len(self.tokens))
        self.i += 1

    def prev_token(self):
        """\
        helper function: syntactic sugar to fetch previous token
        """
        assert(self.i - 1 >= 0)
        return self.tokens[self.i - 1]

    def parse(self, tokens, limit = 3):
        """\
        recursive descent entry point
        @tokens: list of tokens provided by lexical analysis, tokens[-1] == EOF
        @limit: internal ErrorHandler limit
        """
        self.err = ErrorHandler(limit)
        self.tokens = tokens
        self.i = 0
        self.ast = self.expression()

        return (self.ast, self.err)

    def expression(self):
        """\
        dummy method used to encode the lox grammar explicity in the source.
        <expression> := <equality>
        """
        return self.equality()

    def equality(self):
        """\
        <equality> := <comparison> (("==" | "!=") <comparison>)*
        """
        expr = self.comparison()

        types = set([TokenType.EQUAL_EQUAL, TokenType.BANG_EQUAL])

        while self.curr_type() in types:
            self.advance()

            left = expr
            operator = self.prev_token()
            right = self.comparison()

            expr = Binary(left, operator, right)

        return expr

    def comparison(self):
        """\
        <comparison> := <term> ((">" | "<" | "<=" | ">=") <term>)*
        """
        expr = self.term()

        types = set([TokenType.GREATER, TokenType.GREATER_EQUAL, \
                     TokenType.LESS, TokenType.LESS_EQUAL])

        while self.curr_type() in types:
            self.advance()

            left = expr
            operator = self.prev_token()
            right = self.term()

            expr = Binary(left, operator, right)

        return expr

    def term(self):
        """\
        <term> := <factor> (("+" | "-") <factor>)*
        """
        expr = self.factor()

        while self.curr_type() in set([TokenType.PLUS, TokenType.MINUS]):
            self.advance()

            left = expr
            operator = self.prev_token()
            right = self.factor()

            expr = Binary(left, operator, right)

        return expr

    def factor(self):
        """\
        <factor> := <unary> (("*" | "/") <unary>)*
        """
        expr = self.unary()

        while self.curr_type() in set([TokenType.STAR, TokenType.SLASH]):
            self.advance()

            left = expr
            operator = self.prev_token()
            right = self.unary()

            expr = Binary(left, operator, right)

        return expr

    def unary(self):
        """\
        <unary> := ("!" | "-") <unary> | <primary>
        """
        if self.curr_type() in set([TokenType.BANG, TokenType.MINUS]):
            self.advance()
            return Unary(self.prev_token(), self.unary())

        return self.primary()

    def primary(self):
        """\
        <primary> := NUMBER | STRING | "true" | "false" | "nil"
        <primary> := "(" <expression> ")"
        """
        types = set([TokenType.NUMBER, TokenType.STRING, TokenType.NIL, \
                     TokenType.TRUE, TokenType.FALSE])

        if self.curr_type() in types:
            expr = Literal(self.curr_token())
            self.advance()
        elif self.curr_type() == TokenType.LEFT_PAREN:
            self.advance()
            expr = Grouping(self.expression())

            if self.curr_type() == TokenType.RIGHT_PAREN:
                self.advance()
            else:
                self.trap("missing right parenthesis for grouped expression")
                #assume that the parenthesis should have been there
                #continue parsing at the next token
        else:
            lexeme = (self.tokens[self.i]).lexeme
            self.trap("misplaced symbol {}".format(lexeme))

        return expr

    def trap(self, msg):
        """\
        push parameters to error handler then enter panic mode to reset at the
        next sequence point.
        """
        tok = self.tokens[self.i]
        line = tok.line

        if not self.err.push(line, msg):
            self.err.grow(1)
            self.error.push(line, "additional errors found (hidden)")
